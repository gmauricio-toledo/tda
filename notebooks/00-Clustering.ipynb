{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/tda/blob/main/notebooks/00-Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdQaBQt7UC-X"
      },
      "source": [
        "<h1>Clustering</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpuaRVvnUC-c"
      },
      "source": [
        "* El an√°lisis de agrupamiento, o agrupamiento, es una tarea de aprendizaje autom√°tico no supervisada.\n",
        "\n",
        "* Implica descubrir autom√°ticamente la agrupaci√≥n natural de los datos. A diferencia del aprendizaje supervisado (como el modelado predictivo), los algoritmos de agrupaci√≥n solo interpretan los datos de entrada y encuentran grupos o agrupaciones naturales en el espacio de caracter√≠sticas.\n",
        "\n",
        "* Un cluster es un en el espacio de caracter√≠sticas donde las instancias est√°n m√°s cerca del grupo que de otros grupos.\n",
        "\n",
        "* Es probable que estos grupos reflejen alg√∫n mecanismo en funcionamiento en el dominio del que se extraen las instancias, un mecanismo que hace que algunas instancias tengan un parecido m√°s fuerte entre s√≠ que con las instancias restantes.\n",
        "\n",
        "* La agrupaci√≥n en cl√∫sters puede ser √∫til como actividad de an√°lisis de datos para obtener m√°s informaci√≥n sobre el dominio del problema, el llamado descubrimiento de patrones o descubrimiento de conocimiento.\n",
        "\n",
        "* El agrupamiento tambi√©n puede ser √∫til como un tipo de ingenier√≠a de caracter√≠sticas, donde los ejemplos existentes y nuevos se pueden mapear y etiquetar como pertenecientes a uno de los grupos identificados en los datos.\n",
        "\n",
        "* La evaluaci√≥n de los grupos identificados es subjetiva y puede requerir un experto en el dominio, aunque existen muchas medidas cuantitativas espec√≠ficas de los grupos.\n",
        "\n",
        "&#128214; <u>Referencias bibliogr√°ficas</u>:\n",
        "* Flach, Peter (2012). Machine Learning: The Art and Science of Algorithms that Make Sense of Data. Cambridge University Press.\n",
        "\n",
        "[Algoritmos de clustering en scikit-learn](https://scikit-learn.org/stable/modules/clustering.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy_dshVLUC-g"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 0"
      ],
      "metadata": {
        "id": "a24-mU6zlHj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, _ = make_blobs(n_samples=300,\n",
        "                  n_features=2,\n",
        "                  centers=3,\n",
        "                  random_state=3145)\n",
        "\n",
        "# X, _ = make_moons(n_samples=300,\n",
        "#                   noise=0.05, random_state=42)\n",
        "\n",
        "# X, _ = make_circles(n_samples=300,\n",
        "#                     noise=0.05, random_state=42)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4MakoTUSlHMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "clustering = KMeans(n_clusters=2)\n",
        "# clustering = AgglomerativeClustering(n_clusters=2)\n",
        "# clutering = DBSCAN(eps=0.13, min_samples=10)\n",
        "\n",
        "clustering.fit(X)\n",
        "clusters = clustering.labels_\n",
        "\n",
        "silueta = silhouette_score(X,clusters)\n",
        "print(f\"Silueta: {silueta}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1],c=clusters)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7JAzqSAZEEFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el punto de datos $i \\in C_i$, se denota por $a(i)$, la distancia promedio de $i$ a todos los dem√°s puntos en ese cl√∫ster:\n",
        "\n",
        "$$\n",
        "a(i) = \\frac{1}{|C_i| - 1} \\sum_{j \\in C_i, \\, i \\neq j} d(i, j)\n",
        "$$\n",
        "\n",
        "donde $|C_i|$ es el n√∫mero de puntos que pertenecen al cl√∫ster $C_i$, y $d(i,j)$ es la distancia entre los puntos de datos $ i$ y $j$ en el cl√∫ster $C_i$. $a(i)$ puede interpretarse como una medida de qu√© tan bien est√° asignado $i$ a su cl√∫ster (cuanto menor sea el valor, mejor ser√° la asignaci√≥n).\n",
        "\n",
        "Luego, definimos la disimilitud media del punto $i$ a alg√∫n cl√∫ster $C_j$ como la media de la distancia de $i$ a todos los puntos en $C_j$ (donde $C_j \\neq C_i$).\n",
        "\n",
        "Para cada punto de datos $i \\in C_i$, definimos $b(i)$ como la distancia promedio entre $i$ y los puntos del cl√∫ster m√°s cercano (de ah√≠ el \"min\") al que $i$ no pertenece:\n",
        "\n",
        "$$b(i) = \\min_{j \\neq i} \\frac{1}{|C_j|} \\sum_{l \\in C_j} d(i, l)$$\n",
        "\n",
        "El cl√∫ster con la menor disimilitud media se considera el \"cl√∫ster vecino\" de $i$, ya que es el siguiente mejor ajuste para el punto $i$.\n",
        "\n",
        "Finalmente, definimos el valor de la ''silueta'' para un punto de datos $i$:\n",
        "\n",
        "$$s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}, \\quad \\text{si } |C_i| > 1$$\n"
      ],
      "metadata": {
        "id": "fzN8LI51M4uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "# Function to plot k-distance graph\n",
        "def plot_k_distance_graph(X, k):\n",
        "    neigh = NearestNeighbors(n_neighbors=k)\n",
        "    neigh.fit(X)\n",
        "    distances, _ = neigh.kneighbors(X)\n",
        "    distances = np.sort(distances[:, k-1])\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(distances)\n",
        "    plt.xlabel('Points')\n",
        "    plt.ylabel(f'{k}-th nearest neighbor distance')\n",
        "    plt.title('K-distance Graph')\n",
        "    plt.show()\n",
        "# Plot k-distance graph\n",
        "plot_k_distance_graph(X, k=5)"
      ],
      "metadata": {
        "id": "TNAD2DyqFkz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 1: Documentos de Wikipedia\n",
        "\n",
        "Usaremos otra vez el dataset de documentos de Wikipedia, tomaremos la versi√≥n parcial y preprocesada de la sesi√≥n pasada.\n",
        "\n",
        "El objetivo de la pr√°ctica es hacer **Topic Modelling**, es decir segmentar los documentos en grupos con tem√°ticas similares. Para esto, usaremos algoritmos de clustering aplicados a representaciones vectoriales de los documentos. Si las representaciones vectoriales de los documentos son *buenas*, lograremos este objetivo.\n",
        "\n",
        "Al final evaluaremos usamos m√©tricas de clustering y visualizando t√≥picos manualmente\n",
        "\n",
        "**El dataset no tiene una variable target** Estamos en aprendizaje no supervisado"
      ],
      "metadata": {
        "id": "baK_yZkgTibB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1GZeXRqaOTf9zQg8GIJMuGTtnkRLicLug\n",
        "!gdown 1kvdbFQF9G1LTmcTVEPPy57nJRTuT2Kkt\n",
        "!gdown 1x-cchU5867nLouPWjBHOLhfW1w1f0Uq0"
      ],
      "metadata": {
        "id": "vy_MugDLg2Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fname = \"wikipedia_batch_001_cleantext.csv\"\n",
        "df = pd.read_csv(fname)\n",
        "df"
      ],
      "metadata": {
        "id": "ON51TIO0Tj6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.load(\"wikipedia_batch_001_embeddings.npy\")\n",
        "\n",
        "# random_idxs = np.random.choice(X.shape[0],size=2000,replace=False)\n",
        "# X = X[random_idxs]\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "id": "gAmQF8XNmxR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos reducci√≥n de dimensionalidad"
      ],
      "metadata": {
        "id": "I6zM-rCnhQ3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "docs_list = df['clean text'].values\n",
        "\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X)\n",
        "print(X_pca.shape)"
      ],
      "metadata": {
        "id": "g1r0VLlGUjN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos clustering a las representaciones vectoriales."
      ],
      "metadata": {
        "id": "3Mtik-oKirjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# num_clusters = 13\n",
        "num_clusters = 6\n",
        "\n",
        "clustering = KMeans(n_clusters=num_clusters)\n",
        "clustering.fit(X)\n",
        "clusters = clustering.labels_"
      ],
      "metadata": {
        "id": "Pr19w-riUksN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs_per_cluster = {j:np.where(clusters==j)[0] for j in np.unique(clusters)}\n",
        "documents_per_cluster = {j:docs_list[idxs_per_cluster[j]] for j in np.unique(clusters)}"
      ],
      "metadata": {
        "id": "clyEjbRtVprv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con la finalidad de explorar el contenido de los textos de cada cluster, hacemos una nube de palabras de los documentos de cada cluster. Para esto, usamos el m√≥dulo [wordcloud](https://pypi.org/project/wordcloud/).\n",
        "\n",
        "Aqu√≠ puedes ver [ejemplos de su uso](https://github.com/amueller/word_cloud/tree/main)"
      ],
      "metadata": {
        "id": "_RQzX5gShqcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "fig, axs = plt.subplots(nrows=2,ncols=3,dpi=100)\n",
        "\n",
        "axs = axs.flatten()  # Convierte el array 2D en 1D\n",
        "for k,ax in enumerate(axs):\n",
        "    texts = [x for x in documents_per_cluster[k] if x not in stop_words]\n",
        "    wordcloud = WordCloud().generate(\" \".join(texts))\n",
        "    ax.imshow(wordcloud, interpolation='bilinear')\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(f\"Cluster {k}\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WCmQvHOdd2WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "print(f\"Score de silueta: {silhouette_score(X,clusters)}\")"
      ],
      "metadata": {
        "id": "bHXfJgDrjXg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualicemos el valor de codo"
      ],
      "metadata": {
        "id": "iDT-VcHloush"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_clusters = range(2,20)\n",
        "inercias = []\n",
        "\n",
        "for k in n_clusters:\n",
        "    clustering = KMeans(n_clusters=k)\n",
        "    clustering.fit(X)\n",
        "    inercias.append(clustering.inertia_)\n",
        "\n",
        "plt.plot(range(1,len(inercias)+1),inercias)\n",
        "plt.xlabel(\"N√∫mero de clusters\")\n",
        "plt.ylabel(\"Inercia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3SY9R6ZxossC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimamos algunos documentos de cada cluster:"
      ],
      "metadata": {
        "id": "A5E304ohm1EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j,docs in enumerate(documents_per_cluster.values()):\n",
        "    print(f\"Cluster {j}:\")\n",
        "    for doc in docs[:4]:\n",
        "        print(f\"\\t{doc[:100]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "jxeMnQjAm06V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Reflexiona sobre las siguientes preguntas:\n",
        "\n",
        "* ¬øPuedes ver de qu√© tratan los documentos de cada cluster?\n",
        "* Prueba a cambiar el n√∫mero de clusters.\n",
        "* Prueba a cambiar el n√∫mero de dimensiones de las representaciones vectoriales.\n",
        "* Prueba a cambiar el m√©todo de clustering\n",
        "* En cada tarea de clustering, mide el coeficiente de silueta."
      ],
      "metadata": {
        "id": "HtwoFKxDiL15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 2: Canciones de Spotify"
      ],
      "metadata": {
        "id": "NrEN69yjS9Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este conjunto de datos contiene estad√≠sticas de audio de las 2.000 canciones top de Spotify. Los datos contienen alrededor de 15 columnas que describen la canci√≥n y algunas de sus cualidades. Se incluyen canciones publicadas desde 1956 hasta 2019 de algunos artistas notables y famosos. Estos datos contienen caracter√≠sticas de audio como Danceability, BPM, Liveness, Valence(Positivity) y algunas m√°s:\n",
        "\n",
        "* √çndice: ID\n",
        "* T√≠tulo: Nombre de la pista\n",
        "* Artista: Nombre del artista\n",
        "* G√©nero superior: G√©nero de la pista\n",
        "* A√±o: A√±o de lanzamiento de la pista\n",
        "* Pulsaciones por minuto (BPM): El tempo de la canci√≥n\n",
        "* Energy: La energ√≠a de una canci√≥n: cuanto m√°s alto sea el valor, m√°s energ√©tica ser√° la canci√≥n.\n",
        "* Danceability: Cuanto m√°s alto sea el valor, m√°s f√°cil ser√° bailar esta canci√≥n.\n",
        "* Loudness: Cuanto m√°s alto sea el valor, m√°s fuerte ser√° la canci√≥n.\n",
        "* Liveness: ...\n",
        "* Valence: Cuanto m√°s alto sea el valor, m√°s positivo ser√° el estado de √°nimo de la canci√≥n.\n",
        "* Duraci√≥n: La duraci√≥n de la canci√≥n.\n",
        "* Acousticness: Cuanto m√°s alto sea el valor, m√°s ac√∫stica ser√° la canci√≥n.\n",
        "* Speechiness: Cuanto m√°s alto sea el valor, m√°s palabras habladas contiene la canci√≥n.\n",
        "* Popularity: Cuanto m√°s alto sea el valor, m√°s popular es la canci√≥n.\n",
        "\n",
        "Este dataset se encuentra en [Kaggle](https://www.kaggle.com/datasets/iamsumat/spotify-top-2000s-mega-dataset)\n",
        "\n",
        "Vamos a hacer clustering como estrategia para agrupar canciones por grupos similares con base en sus features num√©ricas.\n",
        "\n",
        "**El dataset no tiene una variable target** Estamos en aprendizaje no supervisado"
      ],
      "metadata": {
        "id": "YUSnLgDc6yxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/spotify-2000.csv'\n",
        "df = pd.read_csv(url,index_col=0,thousands=',')\n",
        "df"
      ],
      "metadata": {
        "id": "2p5rJTnaEKAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos un breve analisis exploratorio"
      ],
      "metadata": {
        "id": "yGU6ZIFh5OyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "AuqCCslwj11Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los g√©neros"
      ],
      "metadata": {
        "id": "vEA4ixrd5tUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generos = df['Top Genre'].unique()\n",
        "print(f\"Hay {len(generos)} g√©neros √∫nicos:\")\n",
        "print(generos)"
      ],
      "metadata": {
        "id": "FUbx_iOg_c7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los rangos de las variables"
      ],
      "metadata": {
        "id": "uLb7QDal5yO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "oRqQgbox70gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A manera de an√°lisis exploratorio, veamos las correlaciones entre variables, ¬øqu√© observamos?"
      ],
      "metadata": {
        "id": "U4-A0tlA9kRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlaciones = df.iloc[:,3:].corr()\n",
        "heatmap(correlaciones)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5of0zRUs9I24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que algunos m√©todos de clustering son susceptibles a la escala de valores, hacemos un escalamiento de las variables num√©ricas.\n",
        "\n",
        "**Haremos clustering con s√≥lo estas variables num√©ricas**"
      ],
      "metadata": {
        "id": "_hud5RYP7zhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "df2 = df[[\"Beats Per Minute (BPM)\", \"Loudness (dB)\",\n",
        "              \"Liveness\", \"Valence\", \"Acousticness\",\n",
        "              \"Speechiness\"]].copy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df2[df2.columns] = scaler.fit_transform(df2[df2.columns])\n",
        "X = df2.values\n",
        "\n",
        "df2.head(3)"
      ],
      "metadata": {
        "id": "N_Tb3EgWTljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "id": "Cdq-yECD-rBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos K-means para segmentar en 10 grupos"
      ],
      "metadata": {
        "id": "cK5a1QqrB03t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "modelo = KMeans(n_clusters=10, n_init='auto')\n",
        "\n",
        "modelo.fit(X)\n",
        "clusters = modelo.labels_\n",
        "\n",
        "print(f\"Las primeras 10 etiquetas: {clusters[:10]}\")"
      ],
      "metadata": {
        "id": "BC2tD2N28yVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integramos la informaci√≥n de los clusters al dataframe original."
      ],
      "metadata": {
        "id": "QGUA-MzoCCDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Music Segments\"] = clusters\n",
        "df[\"Music Segments\"] = df[\"Music Segments\"].map({0: \"Cluster 1\", 1:\n",
        "    \"Cluster 2\", 2: \"Cluster 3\", 3: \"Cluster 4\", 4: \"Cluster 5\",\n",
        "    5: \"Cluster 6\", 6: \"Cluster 7\", 7: \"Cluster 8\",\n",
        "    8: \"Cluster 9\", 9: \"Cluster 10\"})\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "rhHEN2zCUo0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observemos un cluster"
      ],
      "metadata": {
        "id": "dn_xNOGSl4vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = 'Cluster 1'\n",
        "\n",
        "df[df['Music Segments']==cluster][['Artist','Title','Top Genre','Year']]"
      ],
      "metadata": {
        "id": "MCCBqzzVl6-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver los artistas en este cluster"
      ],
      "metadata": {
        "id": "YueDpOXR59u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Music Segments']==cluster]['Artist'].unique()"
      ],
      "metadata": {
        "id": "zEI8jGX86AUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos usando solamente 3 features. Usamos el m√≥dulo [plotly](https://plotly.com/python/) para gr√°ficas interactivas.\n",
        "\n",
        "Otra alternativa es [Bokeh](https://bokeh.org/)."
      ],
      "metadata": {
        "id": "wcoMmKJDCHfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "PLOT = go.Figure()\n",
        "\n",
        "for i in list(df[\"Music Segments\"].unique()):\n",
        "    PLOT.add_trace(go.Scatter3d(x = df[df[\"Music Segments\"]==i]['Beats Per Minute (BPM)'],\n",
        "                                    y = df[df[\"Music Segments\"] ==i]['Energy'],\n",
        "                                    z = df[df[\"Music Segments\"] ==i]['Danceability'],\n",
        "                                    mode = 'markers',marker_size = 6, marker_line_width = 1,\n",
        "                                    name = str(i)))\n",
        "PLOT.update_traces(hovertemplate='Beats Per Minute (BPM): %{x} <br>Energy: %{y} <br>Danceability: %{z}')\n",
        "\n",
        "PLOT.update_layout(width = 800, height = 800, autosize = True, showlegend = True,\n",
        "                   scene = dict(xaxis=dict(title = 'Beats Per Minute (BPM)', titlefont_color = 'black'),\n",
        "                                yaxis=dict(title = 'Energy', titlefont_color = 'black'),\n",
        "                                zaxis=dict(title = 'Danceability', titlefont_color = 'black')),\n",
        "                   font = dict(family = \"Arial\", color  = 'black', size = 12))\n",
        "\n",
        "PLOT.show()"
      ],
      "metadata": {
        "id": "m1dXHIGFUG04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando s√≥lo dos dimensiones:"
      ],
      "metadata": {
        "id": "7okOAKI4GRMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=120)\n",
        "for segment in df[\"Music Segments\"].unique():\n",
        "    plt.scatter(x = df[df[\"Music Segments\"]==segment]['Beats Per Minute (BPM)'],\n",
        "                y = df[df[\"Music Segments\"] ==segment]['Energy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VhzrHq0FYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=120)\n",
        "for segment in df[\"Music Segments\"].unique():\n",
        "    plt.scatter(x = df[df[\"Music Segments\"]==segment]['Danceability'],\n",
        "                y = df[df[\"Music Segments\"] ==segment]['Energy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B5nypRH6GVDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "print(f\"Score de silueta: {silhouette_score(X,clusters)}\")"
      ],
      "metadata": {
        "id": "EKMSEGpXgP5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ï Preguntas:\n",
        "* Siendo K-Means, ¬øpor qu√© se no se ve la separaci√≥n perfecta?\n",
        "\n",
        "‚≠ï Ejercicio 1. Continuando con este m√©todo de K-Means:\n",
        "* ¬øQu√© valor de K es mejor? Puedes usar cualquiera de los 3 criteros de arriba, empezando por el *elbow value*.\n",
        "* Una vez que hayas escogido un valor para $K$, reportar los valores de las m√©tricas de clustering: score de Silueta, [Calinski-Harabasz Index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html#sklearn.metrics.calinski_harabasz_score) y [Davies-Bouldin Index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score).\n",
        "\n",
        "‚≠ï Ejercicio 2:\n",
        "\n",
        "* Repetir el experimento, ahora usando Agglomerative Clustering y DBSCAN.\n",
        "* ¬øPuedes elevar las m√©tricas de clustering? Considera las m√©tricas score de Silueta y [Davies-Bouldin Index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score).\n",
        "* Explora visualmente algunas canciones de los clusters, ¬øtiene sentido el agrupamiento?"
      ],
      "metadata": {
        "id": "ACYNyhKPefTU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2gwkihWG6Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 3: Segmentaci√≥n de clientes\n",
        "\n",
        "l objetivo de este an√°lisis es segmentar a los clientes de un centro comercial en grupos homog√©neos (clusters) basados en su comportamiento y caracter√≠sticas demogr√°ficas, como:\n",
        "\n",
        "* G√©nero\n",
        "* Ingreso anual (Annual Income (k$)).\n",
        "* Gasto en el centro comercial (Spending Score (1-100)).\n",
        "* Edad (Age).\n",
        "\n",
        "Esto permitir√° identificar patrones ocultos y dise√±ar estrategias de marketing personalizadas para cada grupo (ej: ofertas para \"clientes de alto ingreso pero bajo gasto\")."
      ],
      "metadata": {
        "id": "266J2HPStVjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/DCDPUAEM/DCDP/main/03%20Machine%20Learning/data/Mall_Customers.csv\"\n",
        "\n",
        "mall_df = pd.read_csv(url)\n",
        "mall_df.drop(columns=['CustomerID'],inplace=True)\n",
        "original_mall_df = mall_df.copy()\n",
        "mall_df"
      ],
      "metadata": {
        "id": "zQXw8edJtVGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Haz *one-hot encoding* con la variable categ√≥rica usando el m√©todo `get_dummies`, no olvides el hiperpar√°metro `drop_first=True`."
      ],
      "metadata": {
        "id": "UVZgkKvNzMH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mall_df = pd.get_dummies(mall_df,drop_first=True, dtype=int)\n",
        "mall_df"
      ],
      "metadata": {
        "id": "KzjPEqn7zL0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Extrae las variables (features) de cada instancia y define la matrix $X$"
      ],
      "metadata": {
        "id": "DdztEGhxymir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = mall_df.values\n",
        "X.shape"
      ],
      "metadata": {
        "id": "kbL0-bdgwsHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùóAqu√≠ no hay divisi√≥n train\\test"
      ],
      "metadata": {
        "id": "dZ7cZu_t0fv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ **Opcional** Aplica reescalamiento a `X`"
      ],
      "metadata": {
        "id": "h7PYEzMr0NBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = MinMaxScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "eu8R9IIVyyei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Clusteriza las instancias, usa K-Means y prueba con dos valores de tu elecci√≥n para el n√∫mero de clusters"
      ],
      "metadata": {
        "id": "jlpp6dvL0vgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "clustering = KMeans(n_clusters=4)\n",
        "clustering.fit(X)"
      ],
      "metadata": {
        "id": "_22m0QZZ1Bbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Extrae los clusters (es decir, el arreglo que dice a qu√© cluster pertenece cada instancia) con el atributo `labels_`"
      ],
      "metadata": {
        "id": "TWRvAjQi1EPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "clusters = clustering.labels_"
      ],
      "metadata": {
        "id": "kmpJPKSm1Dwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Evalua el clustering usando la m√©trica silueta.\n",
        "\n",
        "**Recuerda que esta m√©trica es un n√∫mero $-1\\leq s\\leq 1$** y entre m√°s alto es mejor."
      ],
      "metadata": {
        "id": "BpfVDI452kEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette_score(X,clusters)"
      ],
      "metadata": {
        "id": "PO4GUT3B2zzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üü¢ Visualicemos los resultados. Dado que no son tantos ejemplos, imprimamos un dataframe mostrando cada uno de los clusters.\n",
        "\n",
        "¬øC√≥mo etiquetarias a cada cluster? Es decir, ¬øqu√© comparten en com√∫n cada cluster?"
      ],
      "metadata": {
        "id": "HewZZXAx1d3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_clusters = np.unique(clusters).shape[0]\n",
        "\n",
        "for i in range(num_clusters):\n",
        "    print(f\"Cluster {i}\")\n",
        "    display(original_mall_df[clusters==i])"
      ],
      "metadata": {
        "id": "ap5WviK71dZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ **Extra**: Hacer reducci√≥n de dimensionalidad usando PCA a dos dimensiones y graficar todas las instancias coloreadas por cluster"
      ],
      "metadata": {
        "id": "JK5cm7LT3Vjf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5k__Yn3mCA_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}