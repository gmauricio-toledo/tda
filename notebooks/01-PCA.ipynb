{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXaBsVs8H+Mw7wEPq045T2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/tda/blob/main/notebooks/01-PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>PCA</h1>\n",
        "\n",
        "En esta notebook analizaremos varios aspectos te贸ricos y pr谩cticos del m茅todo PCA. En particular, mostraremos ejemplos de c贸mo podemos perder informaci贸n topol贸gica del conjunto de datos al hacer reducci贸n de dimensionalidad."
      ],
      "metadata": {
        "id": "mnyS51u_U953"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 驴C贸mo usar PCA?"
      ],
      "metadata": {
        "id": "Cq4AyWSdVKE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un conjunto de datos:"
      ],
      "metadata": {
        "id": "rFprN3SWjNYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "puntos, _ = make_classification(n_samples=150,\n",
        "                                n_features=2,\n",
        "                                n_classes=1,\n",
        "                                n_informative=2,\n",
        "                                n_redundant=0,\n",
        "                                n_clusters_per_class=1,\n",
        "                                scale=[0.5,2],\n",
        "                                random_state=721\n",
        "                                )\n",
        "\n",
        "media = np.mean(puntos, axis=0)  # 驴QU ESTAMOS HACIENDO?\n",
        "\n",
        "#----------- GRAFICAR -----------\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.scatter(puntos[:,0], puntos[:,1],color='gray',s=20)\n",
        "plt.scatter([media[0]],[media[1]],color='red',marker='x', label='Mean') # (?)\n",
        "plt.axhline(y=0, color='k', alpha=0.25)\n",
        "plt.axvline(x=0, color='k', alpha=0.25)\n",
        "plt.axis('equal')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xEdatc2zVNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso de PCA:"
      ],
      "metadata": {
        "id": "2gJjU3mTnmoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos y entrenamos PCA\n",
        "pca = PCA(n_components=2)  # Inicializaci贸n (instanciaci贸n)\n",
        "puntos_pca = pca.fit_transform(puntos)  # Entrenamiento y Transformaci贸n\n",
        "\n",
        "# O por separado:\n",
        "# pca.fit(puntos)  # Entrenamiento\n",
        "# puntos_pca = pca.transform(puntos)  # Transformaci贸n"
      ],
      "metadata": {
        "id": "hmf0pJvdipKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar como podemos consultar informaci贸n relevante sobre el procedimiento en la clase entrenada."
      ],
      "metadata": {
        "id": "FGAhqOIwrOy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consultamos informaci贸n sobre el m茅todo\n",
        "pcs = pca.components_   # Vectores componentes principales (PC)\n",
        "mean = pca.mean_        # Promedio de los puntos\n",
        "\n",
        "pcs.shape, mean.shape"
      ],
      "metadata": {
        "id": "_jolOyQckkIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos la informaci贸n\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1) # Grafica con los datos antes de la transformaci贸n\n",
        "plt.scatter(puntos[:,0], puntos[:,1],color='gray',s=20) # Graficamos cada una de las PC\n",
        "for i in range(2): # Graficamos cada una de las dos componentes principales\n",
        "    v = pcs[i]\n",
        "    plt.arrow(mean[0], mean[1], v[0], v[1], head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
        "plt.scatter([mean[0]],[mean[1]],color='red',marker='x') # Graficamos el promedio\n",
        "plt.axhline(y=0, color='k', alpha=0.25) # El eje X\n",
        "plt.axvline(x=0, color='k', alpha=0.25) # El eje Y\n",
        "plt.axis('equal')\n",
        "plt.subplot(1,2,2) # Gr谩fica con los datos despu茅s de la transformaci贸n\n",
        "plt.scatter(puntos_pca[:,0], puntos_pca[:,1],color='gray',s=20)\n",
        "plt.axhline(y=0, color='k', alpha=0.25)\n",
        "plt.axvline(x=0, color='k', alpha=0.25)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CLR8j7YVjFex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **PENDIENTE**: Veamos que se cumple la condici贸n que impusimos sobre las coordenadas de las proyecciones\n",
        "\n",
        "$$\\sum_{j=1}^d \\beta_j = \\sum_{j=1}^d V^T(x_j - \\mu(A) ) = 0$$"
      ],
      "metadata": {
        "id": "XSB6-LztoRd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(puntos_pca,axis=0)"
      ],
      "metadata": {
        "id": "yLsI6fPLlTn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las componentes principales forman una base ortonormal"
      ],
      "metadata": {
        "id": "nPQHXW5WpDX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(pcs.T,pcs)"
      ],
      "metadata": {
        "id": "3d57kCLbo7iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Varianza explicada de los datos originales"
      ],
      "metadata": {
        "id": "W1uX_xQcp7BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "bwSNFaxNp-Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 驴Qu茅 podr铆amos concluir de la forma de los datos con esta informaci贸n?"
      ],
      "metadata": {
        "id": "C-pEIolMtpkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Inclusi贸n de dimensiones inferiores\n",
        "\n",
        "Supongamos que queremos proyectar un conjunto $A\\subset\\mathbb{R}^D$ en espacios $d_1,d_2$ dimensionales con $d_2< d_1< D$.\n",
        "\n",
        "En lugar de entrenar dos modelos de PCA para $d_1$ y $d_2$ respectivamente, basta con entrenar un modelo para $d_1$ para obtener la reducci贸n $A_{d_1}$. Para encontrar la proyecci贸n a $\\mathbb{R}^{d_2}$ basta con tomar las $d_2$ primeras columas de la representaci贸n matricial de $A_{d_2}$.\n",
        "\n",
        "A continuaci贸n ilustramos experimentalmente esto"
      ],
      "metadata": {
        "id": "m29A5_PZMxca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "puntos, _ = make_classification(n_samples=500,\n",
        "                                n_features=20,\n",
        "                                n_classes=3,\n",
        "                                n_informative=15,\n",
        "                                n_clusters_per_class=2,\n",
        "                                random_state=721\n",
        "                                )\n",
        "\n",
        "puntos.shape\n",
        "\n",
        "pca_15 = PCA(n_components=15)\n",
        "puntos_pca_15 = pca_15.fit_transform(puntos)\n",
        "cum_sum_15_rounded = np.round(np.cumsum(pca_15.explained_variance_ratio_),3)\n",
        "\n",
        "pca_8 = PCA(n_components=8)\n",
        "puntos_pca_8 = pca_8.fit_transform(puntos)\n",
        "cum_sum_8_rounded = np.round(np.cumsum(pca_8.explained_variance_ratio_),3)\n",
        "\n",
        "#---- Comparaci贸n de las varianzas ---\n",
        "comparacion = np.isclose(puntos_pca_8, puntos_pca_15[:,:8]).all()\n",
        "print(f\"Son iguales las primeras 8 columas de la reducci贸n 15-dimensional: {comparacion}\")\n",
        "print(f\"Varianza explicada acumulada de la reducci贸n 15-dimensional:\\n{cum_sum_15_rounded}\")\n",
        "print(f\"Varianza explicada acumulada de la reducci贸n 8-dimensional:\\n{cum_sum_8_rounded}\")"
      ],
      "metadata": {
        "id": "CIM0kFRwMw3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomemos un punto aleatorio y comparemos sus coordenadas"
      ],
      "metadata": {
        "id": "MXenOhfzSpmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(puntos.shape[0],size=1)\n",
        "punto_15d = puntos_pca_15[idx]\n",
        "punto_8d = puntos_pca_8[idx]\n",
        "print(f\"Coordenadas en 15-dimensional:\\n{punto_15d}\")\n",
        "print(f\"Coordenadas en 8-dimensional:\\n{punto_8d}\")"
      ],
      "metadata": {
        "id": "OA8qoRjhSly2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(puntos_pca_15[:,0], puntos_pca_15[:,1],color='gray')\n",
        "plt.title('Primeras dos componentes\\nPCA 15D')\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(puntos_pca_8[:,0], puntos_pca_8[:,1],color='gray')\n",
        "plt.title('Primeras dos componentes\\nPCA 8D')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_RG9NlA4S-SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplos"
      ],
      "metadata": {
        "id": "g5zEYC0LV2jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora veamos varios ejemplos ilustrativos de la reducci贸n de dimensionalidad con PCA:\n",
        "\n",
        "* Datos lineales/no lineales con/sin patrones"
      ],
      "metadata": {
        "id": "DZZ1ncOidhxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "xs = np.random.uniform(size=(100,), low=-1,high=3)\n",
        "\n",
        "#------- un patr贸n en los datos -------------\n",
        "# xs1 = np.random.uniform(size=50, low=-1,high=0)\n",
        "# xs2 = np.random.uniform(size=50, low=2,high=3)\n",
        "# xs = np.hstack((xs1,xs2))\n",
        "\n",
        "ys = -1.5*xs + 2\n",
        "# ys = -1.5*xs + 2 + np.random.normal(size=(100,), scale=0.25)  # Es 煤til para quitar el ruido\n",
        "# ys = -(xs-2)**3 - 0.5*(ys+2)**2  # No funciona bien en datos que no tienen una relaci贸n lineal\n",
        "\n",
        "puntos = np.array([xs,ys]).T\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(puntos)\n",
        "puntos_pca = pca.transform(puntos)\n",
        "\n",
        "pcs = pca.components_\n",
        "mean = pca.mean_\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axs[0].scatter(xs,ys,color='red')\n",
        "axs[0].axhline(y=0, color='k', alpha=0.5)\n",
        "axs[0].axvline(x=0, color='k', alpha=0.5)\n",
        "for i in range(2):\n",
        "    v = pcs[i]\n",
        "    axs[0].arrow(mean[0], mean[1], v[0], v[1], head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
        "axs[0].set_title('Puntos originales')\n",
        "axs[0].axis('equal')\n",
        "axs[1].scatter(puntos_pca[:,0],np.zeros(puntos_pca.shape[0]),color='red')\n",
        "axs[1].axhline(y=0, color='k', alpha=0.5)\n",
        "axs[1].axvline(x=0, color='k', alpha=0.5)\n",
        "axs[1].set_title('Puntos proyectados')\n",
        "axs[1].axis('equal')\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hIkwPATZV5fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un ejemplo con datos en $\\mathbb{R}^3$"
      ],
      "metadata": {
        "id": "QwTMlWawcMTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funci贸n para graficar en HTML puntos en $\\mathbb{R}^3$\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as offline\n",
        "\n",
        "\n",
        "def scatter_plot_3d_plotly(X,y=None,filename='plot3d.html',fig_title='Plot'):\n",
        "    assert X.shape[1] == 3, \"X debe tener 3 dimensiones\"\n",
        "    if y is not None:\n",
        "        assert X.shape[0] == y.shape[0], \"X y y deben tener la misma cantidad de puntos\"\n",
        "    else:\n",
        "        y = np.zeros(X.shape[0])\n",
        "    N = X.shape[0]\n",
        "    # Extraer coordenadas x, y, z\n",
        "    x = X[:, 0]\n",
        "    y = X[:, 1]\n",
        "    z = X[:, 2]\n",
        "\n",
        "    # Crear la figura 3D\n",
        "    fig = go.Figure(data=[go.Scatter3d(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        z=z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=3,\n",
        "            color=y,  # Colorear por valor de clase\n",
        "            colorscale='Viridis',  # Escala de colores\n",
        "            opacity=0.8\n",
        "        ),\n",
        "        text=[f'{y[i]}' for i in range(N)],  # Texto al hacer hover (opcional)\n",
        "        hovertemplate='<b>%{text}</b><extra></extra>'\n",
        "    )])\n",
        "\n",
        "    # Configurar el layout para elementos de interfaz\n",
        "    fig.update_layout(\n",
        "        title=fig_title,\n",
        "        scene=dict(\n",
        "            # Ocultar ejes coordenados\n",
        "            xaxis=dict(\n",
        "                visible=False,\n",
        "                showbackground=False,\n",
        "                showgrid=False,\n",
        "                zeroline=False,\n",
        "            ),\n",
        "            yaxis=dict(\n",
        "                visible=False,\n",
        "                showbackground=False,\n",
        "                showgrid=False,\n",
        "                zeroline=False,\n",
        "            ),\n",
        "            zaxis=dict(\n",
        "                visible=False,\n",
        "                showbackground=False,\n",
        "                showgrid=False,\n",
        "                zeroline=False,\n",
        "            ),\n",
        "            # Configurar c谩mara y aspecto\n",
        "            camera=dict(\n",
        "                up=dict(x=0, y=0, z=1),\n",
        "                center=dict(x=0, y=0, z=0),\n",
        "                eye=dict(x=1.2, y=1.2, z=1.2)\n",
        "            )\n",
        "        ),\n",
        "        # Ocultar elementos de la interfaz\n",
        "        showlegend=False,\n",
        "        margin=dict(l=0, r=0, b=0, t=50),\n",
        "    )\n",
        "    # Guardar como archivo HTML\n",
        "    offline.plot(fig, filename=filename, auto_open=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_2jhvDredyZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "xs = np.random.uniform(size=(200,), low=-1,high=3)\n",
        "ys = np.random.uniform(size=(200,), low=2,high=4)\n",
        "\n",
        "zs = -1.5*xs + 2*xs + np.random.normal(size=(200,), scale=0.1)\n",
        "# zs = 1.5*xs**2 - 2*xs**2 + np.random.normal(size=(200,), scale=0.1)\n",
        "\n",
        "puntos = np.array([xs,ys,zs]).T # Unimos los puntos\n",
        "\n",
        "scatter_plot_3d_plotly(puntos,filename='pca3d-example-3.html',fig_title='Plot') # Usamos la funci贸n para graficar en HTML\n",
        "\n",
        "# PCA 2D y gr谩fica\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(puntos)\n",
        "puntos_pca = pca.transform(puntos)\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.scatter(puntos_pca[:,0], puntos_pca[:,1],color='gray',s=20)\n",
        "plt.axhline(y=0, color='k', alpha=0.25)\n",
        "plt.axvline(x=0, color='k', alpha=0.25)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z4AVRE1LcQND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perdida de propiedades topol贸gicas con PCA\n",
        "\n",
        "Si PCA preservara propiedades topol贸gicas no habr铆a mucha necesidad de desarrollar herramientas del an谩lisis topol贸gico de datos"
      ],
      "metadata": {
        "id": "QiPShlpVlqwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ortho_group\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "\n",
        "def encajar(X,dim_output=50):\n",
        "    n, dim_input = X.shape\n",
        "    dataset = np.zeros((n, dim_output))\n",
        "    dataset[:,:dim_input] = X\n",
        "    # ROTAR CON UNA MATRIZ ALEATORIA Y LUEGO TRASLADAR ALEATORIAMENTE\n",
        "    Q = ortho_group.rvs(dim_output)\n",
        "    dataset = dataset @ Q.T\n",
        "    # traslacion = np.random.randn(dim_output)\n",
        "    # dataset = dataset + traslacion\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "lZMyjYz8g7Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Encuentra un conjunto de datos que tenga un c铆clo de dimensi贸n 1 en alta dimensi贸n tal que se pierda este ciclo al proyectar a 2D haciendo PCA"
      ],
      "metadata": {
        "id": "ROYzFZzXmluZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts = np.random.uniform(size=(500,), low=0,high=2*np.pi)\n",
        "xs = np.sin(ts)\n",
        "ys = 0.3*np.cos(ts)\n",
        "zs = np.random.uniform(size=(500,), low=-1,high=1)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(xs,ys,color='gray',s=20)\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "dim = 300\n",
        "\n",
        "X = np.zeros((500,3))\n",
        "X[:,0] = xs\n",
        "X[:,1] = ys\n",
        "X[:,2] = zs\n",
        "\n",
        "scatter_plot_3d_plotly(X,filename='cilindro_ruido_3d.html',fig_title='Plot')\n",
        "\n",
        "X = encajar(X,dim_output=300)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)\n",
        "X_pca = pca.transform(X)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_pca[:,0],X_pca[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R6B4HeFfgFTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=3)\n",
        "pca.fit(X)\n",
        "X_pca = pca.transform(X)\n",
        "scatter_plot_3d_plotly(X_pca,filename='cilindro_ruido_PCA3d.html',fig_title='Plot')"
      ],
      "metadata": {
        "id": "D5zsNysqm4xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Efecto de PCA en una tarea de regresi贸n"
      ],
      "metadata": {
        "id": "HNU0BEwZfYPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el efecto de la reducci贸n de dimensionalidad en una tarea de regresi贸n"
      ],
      "metadata": {
        "id": "hZ6HPpxCfbW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset"
      ],
      "metadata": {
        "id": "fczTQXfigZXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_path = '/content/sample_data/california_housing_train.csv'\n",
        "test_path = '/content/sample_data/california_housing_test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "train_df"
      ],
      "metadata": {
        "id": "kjQC6_4_fSkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos en $X$, $y$"
      ],
      "metadata": {
        "id": "XWibszqGga9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(columns=['median_house_value']).values\n",
        "X_test = test_df.drop(columns=['median_house_value']).values\n",
        "y_train = train_df['median_house_value'].values\n",
        "y_test = test_df['median_house_value'].values\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "Yv3lCvMtigU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA 2d"
      ],
      "metadata": {
        "id": "2eGK3nTLgd0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "eiH1r50EipjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_train_pca[:,0],X_train_pca[:,1],color='red',label='train')\n",
        "plt.scatter(X_test_pca[:,0],X_test_pca[:,1],color='blue',label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7lmKvp1Ni4gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Observar la distribuci贸n de datos de entranamiento y prueba"
      ],
      "metadata": {
        "id": "wdNmVoSFjDU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.scatter(X_train_pca[:,0],X_train_pca[:,1],c=y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "61mjn6xdjDAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparaci贸n regresi贸n con el dataset original y PCA"
      ],
      "metadata": {
        "id": "a-OOBJmhghIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "train_mae = mean_absolute_error(y_train,y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test,y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")"
      ],
      "metadata": {
        "id": "OLUXkRNxjAF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_pca,y_train)\n",
        "y_train_pred = lr.predict(X_train_pca)\n",
        "y_test_pred = lr.predict(X_test_pca)\n",
        "\n",
        "train_mae = mean_absolute_error(y_train,y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test,y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")"
      ],
      "metadata": {
        "id": "dhalFv0ejfd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca_full = PCA(n_components=8)\n",
        "pca_full.fit(X_train)\n",
        "print(pca_full.explained_variance_ratio_)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pca_full.explained_variance_ratio_)\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uz-oPyH8K6ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploremos el efecto del n煤mero del n煤mero de componentes en el error de las predicciones"
      ],
      "metadata": {
        "id": "21D1CqKqM8Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "X_train_pca_full = pca_full.transform(X_train)\n",
        "X_test_pca_full = pca_full.transform(X_test)\n",
        "\n",
        "train_maes = []\n",
        "test_maes = []\n",
        "\n",
        "for k in range(1,9):\n",
        "    X_train_pca_k = X_train_pca_full[:,:k]\n",
        "    X_test_pca_k = X_test_pca_full[:,:k]\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train_pca_k,y_train)\n",
        "    y_train_pred = lr.predict(X_train_pca_k)\n",
        "    y_test_pred = lr.predict(X_test_pca_k)\n",
        "    train_mae = mean_absolute_error(y_train,y_train_pred)\n",
        "    test_mae = mean_absolute_error(y_test,y_test_pred)\n",
        "    train_maes.append(train_mae)\n",
        "    test_maes.append(test_mae)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_maes,label='train')\n",
        "plt.plot(test_maes,label='test')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('MAE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iD7ErUulLNRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparaci贸n de regresi贸n con el dataset original y selecci贸n de variables"
      ],
      "metadata": {
        "id": "UfMkUSLngof0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora intentemos probar con selecci贸n de variables, es decir, proyecciones can贸nicas en los ejes"
      ],
      "metadata": {
        "id": "ZWyK4HswNUGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "train_maes = []\n",
        "test_maes = []\n",
        "\n",
        "for k in range(1,9):\n",
        "    # Selecci贸n de variables\n",
        "    selector = SelectKBest(f_regression, k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "    # Entrenamiento del modelo\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train_selected,y_train)\n",
        "    # Predicci贸n\n",
        "    y_train_pred = lr.predict(X_train_selected)\n",
        "    y_test_pred = lr.predict(X_test_selected)\n",
        "    # Evaluaci贸n\n",
        "    train_mae = mean_absolute_error(y_train,y_train_pred)\n",
        "    test_mae = mean_absolute_error(y_test,y_test_pred)\n",
        "    train_maes.append(train_mae)\n",
        "    test_maes.append(test_mae)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_maes,label='train')\n",
        "plt.plot(test_maes,label='test')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('MAE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cmRnFg_NM4bZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}